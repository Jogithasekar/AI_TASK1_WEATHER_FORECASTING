# -*- coding: utf-8 -*-
"""TASK1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SMgGNGx-ou0I3PqTHnHv25C_kQzuI_X7
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras import models, layers

# 1. Load Weather Dataset
df = pd.read_csv("/content/seattle-weather.csv")   # <-- your file name
print(df.head())

# 2. Separate Features & Target
df["temperature"] = (df["temp_max"] + df["temp_min"]) / 2

X = df.drop(["temperature", "date", "weather"], axis=1)
y = df["temperature"]

# 3. Normalize (MinMax Scaling)
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# 4. Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# 5. Build Neural Network
model = models.Sequential([
    layers.Input(shape=(X_train.shape[1],)),
    layers.Dense(64, activation="relu"),
    layers.Dense(32, activation="relu"),
    layers.Dense(1)
])
model.compile(optimizer="adam", loss="mse")

# 6. Train with N EPOCHS
n = 50   # <-- change this value anytime
history = model.fit(X_train, y_train, epochs=n, batch_size=32, validation_split=0.2)

# 7. Plot Loss Curve
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Val Loss")
plt.title("Training Loss vs Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.legend()
plt.show()

from sklearn.metrics import mean_absolute_error, mean_squared_error

# 8. Predict on test data
y_pred = model.predict(X_test)

# 9. Calculate loss values manually
MAE = mean_absolute_error(y_test, y_pred)
MSE = mean_squared_error(y_test, y_pred)
RMSE = np.sqrt(MSE)

print("----- LOSS VALUES -----")
print("MAE : ", MAE)
print("MSE : ", MSE)
print("RMSE:", RMSE)